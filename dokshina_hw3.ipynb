{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 27 ноября 2017, 23:59   \n",
    "**Штраф за опоздание:** -2 балла после 23:59  4 декабря, -4 балла после 23:59 11 декабря, -6 баллов после 23:59 18 декабря\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw1.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбаловка:**   \n",
    "За задание можно получить 10 баллов. Для этого нужно следующее:\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает    \n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала качественнее, чем у дерева из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print 'invalid criterion name'\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print 'invalid max_features name'\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - (np.sum(l_c * l_c / l_s + r_c * r_c / r_s, axis=1)).reshape(-1, 1) / (l_s + r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        EPS = 1e-5\n",
    "        return - (np.sum(l_c * np.log((l_c + EPS) / l_s) + \n",
    "                                r_c * np.log((r_c + EPS) / r_s), axis=1)).reshape(-1, 1) / (l_s + r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - (np.max(l_c, axis=1) + np.max(r_c, axis=1)).reshape(-1, 1) / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log2(1 + n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def __make_leaf(self, node_id, y):\n",
    "        class_sizes = np.bincount(y, minlength=self.num_class)        \n",
    "        self.tree[node_id] = [\n",
    "            self.__class__.LEAF_TYPE, \n",
    "            np.argmax(class_sizes),\n",
    "            class_sizes / np.sum(class_sizes).astype('float')\n",
    "        ]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # Сортрирует x и y по возрастанию x, определяет число различных классов\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Обрезает отсортированный y так, чтобы при разделении нигде не осталось\n",
    "        # меньше точек, чем задано в min_samples_split\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        # Граничные индексы - где классы меняются (правая граница идущих подряд элементов одного класса...\n",
    "        # ... которая после + (self.min_samples_split + 1) становится левой границей следующих элементов\n",
    "        # для того, чтобы потом хорошо определились размеры частей при разбиении\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        # Классы не меняются нигде\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Находит число подряд идущих одинаковых эелементов (кроме последней группы, но это и не надо)\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        \n",
    "        # r_border_ids.shape[0] - число мест, где можно разбить выборку\n",
    "        # one_hot_code - матрица: i-я строка содержит 1 в j столбце, если i-й по счету отрезок имеет лейбл j\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        \n",
    "        # Не просто one_hot, а еще и знаем, сколько элементов \n",
    "        # class_increments[i, j] = n, если i-й по счету отрезок содержит n элементов лейбла j\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        # Добавили то, что отрезалось в начале sorted_y, когда делали splitted_sorted_y\n",
    "        # чтобы знать, сколько элементов каждого класса остается слева при новом разбиении \n",
    "        # и не потерять то что сплитнули\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Считаем сколько элементов каждого класса будет оставаться слева и справа при разбиении по каждой границе\n",
    "        l_class_count = np.cumsum(class_increments, axis=0) \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        \n",
    "        # Сколько элементов всех классов будет оставаться слева  и справа при разбиении по каждой границе\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Ищем, при разбиении по какой границе impurity наилучшее\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "    \n",
    "        # Что делает этот блок кода?\n",
    "        # Номер элемента, с которого начнется правый класс при разбиении\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        # Вернем лучшее impurity и среднее между граничными элементами - threshold\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE +\n",
    "        # self.NON_LEAF_TYPE\n",
    "\n",
    "        # self.tree+\n",
    "        # self.max_depth+\n",
    "        # self.sufficient_share ?\n",
    "        # self.min_samples_split+\n",
    "\n",
    "        # self.get_feature_ids+\n",
    "        # self.__find_threshold+\n",
    "        # self.__div_samples+\n",
    "        # self.__fit_node+\n",
    "        \n",
    "        \n",
    "        if depth == self.max_depth or x.shape[0] < self.min_samples_split:\n",
    "            self.__make_leaf(node_id, y)\n",
    "            return\n",
    "        \n",
    "        features = self.get_feature_ids(x.shape[1])\n",
    "        thresholds = []\n",
    "        impuritys = []\n",
    "        \n",
    "        for feature_id in features:\n",
    "            gs, threshold = self.__find_threshold(x[:, feature_id], y)\n",
    "            thresholds.append(threshold)\n",
    "            impuritys.append(gs)\n",
    "        \n",
    "        best_feature = features[np.argmin(impuritys)]\n",
    "        best_impurity = np.min(impuritys)\n",
    "        best_threshold = thresholds[np.argmin(impuritys)]\n",
    "        \n",
    "        if best_impurity == float('+inf'):\n",
    "            self.__make_leaf(node_id, y)\n",
    "            return\n",
    "            \n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, best_feature, best_threshold)\n",
    "        \n",
    "        if y_l.shape[0] == 0 or y_r.shape[0] == 0:\n",
    "            self.__make_leaf(node_id, y)\n",
    "            return\n",
    "        \n",
    "        self.tree[node_id] = [\n",
    "            self.__class__.NON_LEAF_TYPE,\n",
    "            best_feature,\n",
    "            best_threshold\n",
    "        ]\n",
    "        \n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)            \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def test(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.469061136246\n",
      "1.05729699135\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932360522158\n",
      "0.931861644633\n",
      "0.931154901472\n",
      "0.933690862227\n",
      "0.933313931734\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893448075164\n",
      "0.890662675646\n",
      "0.890413236884\n",
      "0.890080651867\n",
      "0.891531201929\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
